{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# V2EX Post Analysis Notebook\n",
        "\n",
        "This notebook processes V2EX post data by applying LLM-based analysis to each chunk of text within the JSON files. It adds the analysis results to each chunk and writes the modified data to new JSON files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_drive_header"
      },
      "source": [
        "## Setup Google Drive\n",
        "\n",
        "First, let's mount Google Drive to save our work there. This will help prevent data loss if the Colab session is interrupted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mount_drive"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a directory for our project in Google Drive\n",
        "!mkdir -p /content/drive/MyDrive/v2ex_analysis/posts_json_analyzed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "## Setup Dependencies\n",
        "\n",
        "Now, we'll install the required dependencies and set up the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_dependencies"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch transformers tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_files_header"
      },
      "source": [
        "## Download Files\n",
        "\n",
        "Next, we'll download the analysis script and the JSON files from GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_files"
      },
      "outputs": [],
      "source": [
        "# Clone the repository to get the JSON files and script\n",
        "!git clone https://github.com/baoliqi/v2ex-digest-pages.git\n",
        "\n",
        "# Change to the repository directory\n",
        "%cd v2ex-digest-pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_files_header"
      },
      "source": [
        "## Check Files\n",
        "\n",
        "Let's check that we have the necessary files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_files"
      },
      "outputs": [],
      "source": [
        "# Check that we have the analysis script\n",
        "!ls -la analyze_posts.py\n",
        "\n",
        "# Check that we have the JSON files\n",
        "!ls -la docs/posts_json/ | head -n 10\n",
        "\n",
        "# Check if we already have any analyzed files in Google Drive\n",
        "!ls -la /content/drive/MyDrive/v2ex_analysis/posts_json_analyzed/ || echo \"No files yet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_analysis_header"
      },
      "source": [
        "## Run Analysis\n",
        "\n",
        "Now we'll run the analysis script to process the JSON files. We'll check for existing output files and skip them to avoid redundant processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_analysis"
      },
      "outputs": [],
      "source": [
        "# Run the analysis script with output to Google Drive\n",
        "# Note: We don't use the --force flag so it will skip files that already exist\n",
        "!python analyze_posts.py --output_dir /content/drive/MyDrive/v2ex_analysis/posts_json_analyzed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check_results_header"
      },
      "source": [
        "## Check Results\n",
        "\n",
        "Let's check the results to make sure the analysis was successful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_results"
      },
      "outputs": [],
      "source": [
        "# Check that we have the output files in Google Drive\n",
        "!ls -la /content/drive/MyDrive/v2ex_analysis/posts_json_analyzed/ | head -n 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_results_header"
      },
      "source": [
        "## Download Results\n",
        "\n",
        "Finally, let's download the results to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# Create a zip file of the results from Google Drive\n",
        "!zip -r posts_json_analyzed.zip /content/drive/MyDrive/v2ex_analysis/posts_json_analyzed/\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('posts_json_analyzed.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
